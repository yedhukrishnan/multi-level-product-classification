{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "import json\n",
    "import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>clean_name</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alisha Solid Women's Cycling Shorts</td>\n",
       "      <td>alisha solid womens cycling shorts</td>\n",
       "      <td>Clothing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alisha Solid Women's Cycling Shorts</td>\n",
       "      <td>alisha solid womens cycling shorts</td>\n",
       "      <td>Women's Clothing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FabHomeDecor Fabric Double Sofa Bed</td>\n",
       "      <td>fabhomedecor fabric double sofa bed</td>\n",
       "      <td>Furniture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FabHomeDecor Fabric Double Sofa Bed</td>\n",
       "      <td>fabhomedecor fabric double sofa bed</td>\n",
       "      <td>Living Room Furniture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AW Bellies</td>\n",
       "      <td>aw bellies</td>\n",
       "      <td>Footwear</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  name                           clean_name  \\\n",
       "0  Alisha Solid Women's Cycling Shorts   alisha solid womens cycling shorts   \n",
       "1  Alisha Solid Women's Cycling Shorts   alisha solid womens cycling shorts   \n",
       "2  FabHomeDecor Fabric Double Sofa Bed  fabhomedecor fabric double sofa bed   \n",
       "3  FabHomeDecor Fabric Double Sofa Bed  fabhomedecor fabric double sofa bed   \n",
       "4                           AW Bellies                           aw bellies   \n",
       "\n",
       "                category  \n",
       "0               Clothing  \n",
       "1       Women's Clothing  \n",
       "2              Furniture  \n",
       "3  Living Room Furniture  \n",
       "4               Footwear  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "products = pd.read_csv('products_list.csv')\n",
    "products.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Clothing                      3028\n",
       "Women's Clothing              2017\n",
       "Jewellery                     1956\n",
       "Automotive                     977\n",
       "Accessories & Spare parts      907\n",
       "                              ... \n",
       "HH Oval Sunglasses               1\n",
       "REMSON INDIA Women Flats         1\n",
       "Clocks                           1\n",
       "Kitchen & Dining Furniture       1\n",
       "Olvin Aviator Sunglasses         1\n",
       "Name: category, Length: 72, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "products.category.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of unique tokens: 6093\n"
     ]
    }
   ],
   "source": [
    "tokenizer = Tokenizer(\n",
    "    num_words=None, filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n', lower=True,\n",
    "    split=' ', char_level=False, oov_token=None, document_count=0\n",
    ")\n",
    "tokenizer.fit_on_texts(products['clean_name'].values)\n",
    "word_index = tokenizer.word_index\n",
    "print('Count of unique tokens: %s' % len(word_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the tokenizer which will be used in training and prediction\n",
    "tokenizer_json = tokenizer.to_json()\n",
    "with io.open('tokenizer.json', 'w', encoding='utf-8') as f:\n",
    "    f.write(json.dumps(tokenizer_json, ensure_ascii=False))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
